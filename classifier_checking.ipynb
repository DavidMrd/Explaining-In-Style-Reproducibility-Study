{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n",
      "  Using cached https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n",
      "Requirement already satisfied (use --upgrade to upgrade): torchsampler==0.1.1 from https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages\n",
      "Requirement already satisfied: pandas in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from torchsampler==0.1.1) (1.3.4)\n",
      "Requirement already satisfied: torch>=1.3 in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from torchsampler==0.1.1) (1.10.0+cu113)\n",
      "Requirement already satisfied: torchvision>=0.5 in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from torchsampler==0.1.1) (0.11.1+cu113)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from pandas->torchsampler==0.1.1) (1.21.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from pandas->torchsampler==0.1.1) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from pandas->torchsampler==0.1.1) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from torch>=1.3->torchsampler==0.1.1) (4.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from torchvision>=0.5->torchsampler==0.1.1) (8.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tannin/Desktop/DL1/.venv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->torchsampler==0.1.1) (1.16.0)\n",
      "Building wheels for collected packages: torchsampler\n",
      "  Building wheel for torchsampler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchsampler: filename=torchsampler-0.1.1-py3-none-any.whl size=3828 sha256=d3a493c4403cecab0ad5cc378d6b69f14dc7b41d279926377aa472e97a6ec489\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nfbbu58i/wheels/90/7e/cd/4f5ece8831ffd9a54a62db046bca608f3a0a514dc47cba0eea\n",
      "Successfully built torchsampler\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tannin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True).to(device)\n",
    "model.classifier[1] = nn.Linear(1280, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(dataset, nclasses):                        \n",
    "    count = [0] * nclasses                                 \n",
    "\n",
    "    for item in dataset:     \n",
    "\n",
    "        if len(item) == 1:\n",
    "            print(item)        \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(dataset)                                              \n",
    "    for idx, val in enumerate(dataset):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.plant_vilage.util import download_plantvillage_dataset, get_train_valid_test_dataset\n",
    "\n",
    "\n",
    "train, val, test = get_train_valid_test_dataset('./plant-village', image_size=64)\n",
    "\n",
    "weights = make_weights_for_balanced_classes(train, 2)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=128, sampler=sampler)\n",
    "val_loader = DataLoader(val, batch_size=128)\n",
    "test_loader = DataLoader(test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.features.requires_grad_(False)\n",
    "model.classifier.requires_grad_(True)\n",
    "\n",
    "def validate_model(model, loader, criterion):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "\n",
    "    # Set the model to evaluation mode.\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize the loss and accuracy.\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    # For each batch in the validation set...\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # Send the batch to the device.\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Expand image to have 3 channels.\n",
    "\n",
    "        data = data.expand(data.shape[0], 3, data.shape[2], data.shape[3])\n",
    "\n",
    "        # Upscale to 32x32\n",
    "\n",
    "        data = F.interpolate(data, size=(32, 32))\n",
    "\n",
    "        # Forward pass.\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "\n",
    "        # Calculate the loss.\n",
    "        loss += criterion(output, target).item()\n",
    "\n",
    "        # Get the predictions.\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        # Calculate the accuracy.\n",
    "        accuracy += torch.sum(preds == target).item()\n",
    "\n",
    "    # Calculate the average loss and accuracy.\n",
    "    loss /= len(loader) * 128\n",
    "    accuracy /= len(loader) * 128\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=10):\n",
    "    \"\"\"Trains model\"\"\"\n",
    "\n",
    "    # Put the model in training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each epoch...\n",
    "    for epoch in range(epochs):\n",
    "        # For each batch in the training set...\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Send the data and labels to the device.\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Expand image to have 3 channels.\n",
    "\n",
    "            data = data.expand(data.shape[0], 3, data.shape[2], data.shape[3])\n",
    "\n",
    "            # Upscale to 32x32\n",
    "\n",
    "            data = F.interpolate(data, size=(32, 32))\n",
    "\n",
    "\n",
    "            # Zero out the gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass.\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Backward pass.\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the loss.\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(epoch + 1, epochs),\n",
    "                      'Loss: {:.4f}'.format(loss.item()))\n",
    "\n",
    "        # Validate the model.\n",
    "        val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
    "\n",
    "        # Print the validation loss.\n",
    "        print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "\n",
    "        # Print the validation accuracy.\n",
    "        print('Validation Accuracy: {:.4f}'.format(val_acc))\n",
    "\n",
    "    # Test the model.\n",
    "    test_loss, test_acc = validate_model(model, test_loader, criterion)\n",
    "\n",
    "    # Print the test loss.\n",
    "    print('Test Loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "    # Print the test accuracy.\n",
    "    print('Test Accuracy: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze/unfreeze layers after converging with training\n",
    "\n",
    "model.features[0:13].requires_grad_(False)\n",
    "model.features[13:].requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 Loss: 0.0440\n",
      "Epoch: 1/1 Loss: 0.0523\n",
      "Epoch: 1/1 Loss: 0.0417\n",
      "Validation Loss: 0.0008\n",
      "Validation Accuracy: 0.9619\n",
      "Test Loss: 0.0008\n",
      "Test Accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, criterion, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model state dict to file\n",
    "\n",
    "torch.save(model.state_dict(), './plant-village-64.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_loader = DataLoader(train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = []\n",
    "y_trues = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(_train_loader):\n",
    "        y_preds.append(target.cpu())\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data = data.expand(data.shape[0], 3, data.shape[2], data.shape[3])\n",
    "\n",
    "        data = F.interpolate(data, size=(32, 32))\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        y_trues.append(preds.cpu())\n",
    "    \n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        y_preds.append(target.cpu())\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data = data.expand(data.shape[0], 3, data.shape[2], data.shape[3])\n",
    "\n",
    "        data = F.interpolate(data, size=(32, 32))\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        y_trues.append(preds.cpu())\n",
    "\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        y_preds.append(target.cpu())\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data = data.expand(data.shape[0], 3, data.shape[2], data.shape[3])\n",
    "\n",
    "        data = F.interpolate(data, size=(32, 32))\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        y_trues.append(preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.concatenate(y_preds)\n",
    "y_trues = np.concatenate(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_trues, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14805,   667],\n",
       "       [  279, 38554]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9568898655635988"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14805 / (14805 + 667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa3962ee0560444ad985082d3a9d1d3cf5b3a106c0ad670dbb0d52cc4dc0741"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
