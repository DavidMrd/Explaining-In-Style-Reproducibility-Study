{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:14:53.682044Z",
     "iopub.status.busy": "2022-02-02T13:14:53.681794Z",
     "iopub.status.idle": "2022-02-02T13:15:02.419509Z",
     "shell.execute_reply": "2022-02-02T13:15:02.418726Z",
     "shell.execute_reply.started": "2022-02-02T13:14:53.681969Z"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://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@github.com/NoahVl/Explaining-In-Style-Reproducibility-Study.git\n",
    "# %cd Explaining-In-Style-Reproducibility-Study\n",
    "# !git checkout main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:15:02.422792Z",
     "iopub.status.busy": "2022-02-02T13:15:02.422116Z",
     "iopub.status.idle": "2022-02-02T13:16:18.580531Z",
     "shell.execute_reply": "2022-02-02T13:16:18.579720Z",
     "shell.execute_reply.started": "2022-02-02T13:15:02.422758Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install fire\n",
    "# !pip install lpips\n",
    "# !pip install einops\n",
    "# !pip install kornia\n",
    "# !pip install vector_quantize_pytorch\n",
    "# !pip install Pillow\n",
    "# !pip install pathlib\n",
    "# !pip install aim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:18.583486Z",
     "iopub.status.busy": "2022-02-02T13:16:18.582724Z",
     "iopub.status.idle": "2022-02-02T13:16:20.328190Z",
     "shell.execute_reply": "2022-02-02T13:16:20.327462Z",
     "shell.execute_reply.started": "2022-02-02T13:16:18.583442Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import imageio\n",
    "\n",
    "import multiprocessing\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import ast\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "import requests\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copyfile\n",
    "import IPython.display as IPython_display\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:20.330468Z",
     "iopub.status.busy": "2022-02-02T13:16:20.330220Z",
     "iopub.status.idle": "2022-02-02T13:16:22.814390Z",
     "shell.execute_reply": "2022-02-02T13:16:22.813539Z",
     "shell.execute_reply.started": "2022-02-02T13:16:20.330433Z"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working\n",
    "# !mkdir ./trained_classifiers\n",
    "# copyfile(\"../input/facesattfind-all/faces-classifier.pt\", \"./trained_classifiers/faces-classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:22.816136Z",
     "iopub.status.busy": "2022-02-02T13:16:22.815881Z",
     "iopub.status.idle": "2022-02-02T13:16:22.845053Z",
     "shell.execute_reply": "2022-02-02T13:16:22.843945Z",
     "shell.execute_reply.started": "2022-02-02T13:16:22.816101Z"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working\n",
    "# %cd ../input/facesattfind-all\n",
    "from resnet_classifier import ResNet\n",
    "# %cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:22.846513Z",
     "iopub.status.busy": "2022-02-02T13:16:22.846209Z",
     "iopub.status.idle": "2022-02-02T13:16:23.736408Z",
     "shell.execute_reply": "2022-02-02T13:16:23.735668Z",
     "shell.execute_reply.started": "2022-02-02T13:16:22.846475Z"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working\n",
    "# %cd ../input/facesattfind-all\n",
    "\n",
    "# TODO: You guys might want to change this to stylex_train_new\n",
    "from stylex_train import StylEx, Dataset, DistributedSampler, MNIST_1vA\n",
    "from stylex_train import image_noise, styles_def_to_tensor, make_weights_for_balanced_classes, cycle, default\n",
    "# %cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:23.738442Z",
     "iopub.status.busy": "2022-02-02T13:16:23.737952Z",
     "iopub.status.idle": "2022-02-02T13:16:23.749035Z",
     "shell.execute_reply": "2022-02-02T13:16:23.748101Z",
     "shell.execute_reply.started": "2022-02-02T13:16:23.738403Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_hdf5_results(data_file, name, threshold):\n",
    "    return np.array(data_file[name])[0:threshold]\n",
    "\n",
    "def model_loader(stylex_path,\n",
    "                   classifier_name,\n",
    "                   image_size,\n",
    "                   cuda_rank):\n",
    "\n",
    "    stylex = StylEx(image_size=image_size)\n",
    "    stylex.load_state_dict(torch.load(stylex_path)[\"StylEx\"])\n",
    "    classifier = ResNet(classifier_name, cuda_rank=cuda_rank, output_size=2, image_size=image_size)\n",
    "    return stylex, classifier\n",
    "\n",
    "def sindex_to_block_idx_and_index(generator, sindex):\n",
    "    tmp_idx = sindex\n",
    "\n",
    "    block_idx = None\n",
    "    idx = None\n",
    "\n",
    "    for idx, block in enumerate(generator.blocks):\n",
    "        if tmp_idx < block.num_style_coords:\n",
    "            block_idx = idx\n",
    "            idx = tmp_idx\n",
    "            break\n",
    "        else:\n",
    "            tmp_idx = tmp_idx - block.num_style_coords\n",
    "\n",
    "    return block_idx, idx\n",
    "\n",
    "def plot_image(tensor, upscale_res=None):\n",
    "    if upscale_res is not None:\n",
    "        tensor = resize(tensor, upscale_res)\n",
    "    grid = make_grid(tensor,nrow=5)\n",
    "    ndarr = grid.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:23.751030Z",
     "iopub.status.busy": "2022-02-02T13:16:23.750462Z",
     "iopub.status.idle": "2022-02-02T13:16:23.763411Z",
     "shell.execute_reply": "2022-02-02T13:16:23.762693Z",
     "shell.execute_reply.started": "2022-02-02T13:16:23.750992Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "stylex_path = \"./models/Faces-Resnet-ResizeFix64/model_300.pt\"\n",
    "classifier_name='resnet-18-64px-unfreezel4.pt'\n",
    "results_folder = './'\n",
    "threshold_folder = './'\n",
    "dataset_name = None # for any dataset that is not MNIST\n",
    "cuda_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:23.764442Z",
     "iopub.status.busy": "2022-02-02T13:16:23.764253Z",
     "iopub.status.idle": "2022-02-02T13:16:27.187740Z",
     "shell.execute_reply": "2022-02-02T13:16:27.186962Z",
     "shell.execute_reply.started": "2022-02-02T13:16:23.764412Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_index = 501\n",
    "\n",
    "hf = h5py.File('./style_change_records.hdf5', 'r')\n",
    "\n",
    "style_change_effect = load_hdf5_results(hf, \"style_change\", threshold_index)\n",
    "W_values = load_hdf5_results(hf, \"latents\", threshold_index)\n",
    "base_probs = load_hdf5_results(hf, \"base_prob\", threshold_index)\n",
    "all_style_vectors = load_hdf5_results(hf, \"style_coordinates\", threshold_index)\n",
    "original_images = load_hdf5_results(hf, \"original_images\", threshold_index)\n",
    "discriminator_results = load_hdf5_results(hf, \"discriminator\", threshold_index)\n",
    "\n",
    "saved_noise = torch.Tensor(np.array(hf[\"noise\"])).cuda(cuda_rank)\n",
    "style_min = torch.Tensor(np.squeeze(np.array(hf[\"minima\"])))\n",
    "style_max = torch.Tensor(np.squeeze(np.array(hf[\"maxima\"])))\n",
    "\n",
    "all_style_vectors_distances = np.zeros((all_style_vectors.shape[0], all_style_vectors.shape[1], 2))\n",
    "all_style_vectors_distances[:,:, 0] = all_style_vectors - np.tile(style_min, (all_style_vectors.shape[0], 1))\n",
    "all_style_vectors_distances[:,:, 1] = np.tile(style_max, (all_style_vectors.shape[0], 1)) - all_style_vectors\n",
    "\n",
    "style_min = style_min.cuda(cuda_rank)\n",
    "style_max = style_max.cuda(cuda_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:27.190652Z",
     "iopub.status.busy": "2022-02-02T13:16:27.190371Z",
     "iopub.status.idle": "2022-02-02T13:16:27.197475Z",
     "shell.execute_reply": "2022-02-02T13:16:27.196709Z",
     "shell.execute_reply.started": "2022-02-02T13:16:27.190616Z"
    }
   },
   "outputs": [],
   "source": [
    "num_style_coords = len(style_min)\n",
    "image_size = original_images.shape[-1]\n",
    "shift_size = 0.5\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:27.200659Z",
     "iopub.status.busy": "2022-02-02T13:16:27.200432Z",
     "iopub.status.idle": "2022-02-02T13:16:37.729182Z",
     "shell.execute_reply": "2022-02-02T13:16:37.728430Z",
     "shell.execute_reply.started": "2022-02-02T13:16:27.200623Z"
    }
   },
   "outputs": [],
   "source": [
    "stylex, classifier = model_loader(stylex_path = stylex_path,\n",
    "                                  classifier_name = classifier_name,\n",
    "                                  image_size = image_size,\n",
    "                                  cuda_rank = cuda_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:37.730867Z",
     "iopub.status.busy": "2022-02-02T13:16:37.730621Z",
     "iopub.status.idle": "2022-02-02T13:16:37.748330Z",
     "shell.execute_reply": "2022-02-02T13:16:37.745301Z",
     "shell.execute_reply.started": "2022-02-02T13:16:37.730831Z"
    }
   },
   "outputs": [],
   "source": [
    "all_labels = np.argmax(base_probs, axis=1)\n",
    "style_effect_classes = {}\n",
    "W_classes = {}\n",
    "style_vectors_distances_classes = {}\n",
    "all_style_vectors_classes = {}\n",
    "\n",
    "for img_ind in range(2):\n",
    "    \n",
    "    img_inx = np.array([i for i in range(all_labels.shape[0]) if all_labels[i] == img_ind])\n",
    "    curr_style_effect = np.zeros((len(img_inx), style_change_effect.shape[1], style_change_effect.shape[2], style_change_effect.shape[3]))\n",
    "    curr_w = np.zeros((len(img_inx), W_values.shape[1]))\n",
    "    curr_style_vector_distances = np.zeros((len(img_inx), style_change_effect.shape[2], 2))\n",
    "    \n",
    "    for k, i in enumerate(img_inx):\n",
    "        curr_style_effect[k, :, :] = style_change_effect[i, :, :, :]\n",
    "        curr_w[k, :] = W_values[i, :]\n",
    "        curr_style_vector_distances[k, :, :] = all_style_vectors_distances[i, :, :]\n",
    "        \n",
    "    style_effect_classes[img_ind] = curr_style_effect\n",
    "    W_classes[img_ind] = curr_w\n",
    "    style_vectors_distances_classes[img_ind] = curr_style_vector_distances\n",
    "    all_style_vectors_classes[img_ind] = all_style_vectors[img_inx]\n",
    "    print(f'Class {img_ind}, {len(img_inx)} images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:37.749852Z",
     "iopub.status.busy": "2022-02-02T13:16:37.749504Z",
     "iopub.status.idle": "2022-02-02T13:16:37.991969Z",
     "shell.execute_reply": "2022-02-02T13:16:37.991148Z",
     "shell.execute_reply.started": "2022-02-02T13:16:37.749807Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_significant_styles(style_change_effect,\n",
    "                            num_indices,\n",
    "                            class_index,\n",
    "                            generator,\n",
    "                            classifier,\n",
    "                            all_dlatents,\n",
    "                            style_min,\n",
    "                            style_max,\n",
    "                            max_image_effect = 0.2,\n",
    "                            label_size = 2,\n",
    "                            sindex_offset = 0):\n",
    "  \n",
    "    num_images = style_change_effect.shape[0]\n",
    "    style_effect_direction = np.maximum(0, style_change_effect[:, :, :, class_index].reshape((num_images, -1)))\n",
    "\n",
    "    images_effect = np.zeros(num_images)\n",
    "    all_sindices = []\n",
    "    discriminator_removed = []\n",
    "\n",
    "    while len(all_sindices) < num_indices:\n",
    "        next_s = np.argmax(np.mean(style_effect_direction[images_effect < max_image_effect], axis=0))\n",
    "        \n",
    "        all_sindices.append(next_s)\n",
    "        images_effect += style_effect_direction[:, next_s]\n",
    "        style_effect_direction[:, next_s] = 0\n",
    "\n",
    "    return [(x // style_change_effect.shape[2], (x % style_change_effect.shape[2]) + sindex_offset) for x in all_sindices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:37.993967Z",
     "iopub.status.busy": "2022-02-02T13:16:37.993699Z",
     "iopub.status.idle": "2022-02-02T13:16:38.020705Z",
     "shell.execute_reply": "2022-02-02T13:16:38.019949Z",
     "shell.execute_reply.started": "2022-02-02T13:16:37.993930Z"
    }
   },
   "outputs": [],
   "source": [
    "label_size_clasifier = 2\n",
    "num_indices =  10\n",
    "effect_threshold = 0.5\n",
    "s_indices_and_signs_dict = {}\n",
    "\n",
    "for class_index in [0, 1]:\n",
    "    split_ind =  class_index #1 - class_index\n",
    "    all_s = style_effect_classes[split_ind]\n",
    "    all_w = W_classes[split_ind]\n",
    "\n",
    "    # Find s indicies\n",
    "    s_indices_and_signs = find_significant_styles(style_change_effect=all_s,\n",
    "                                                  num_indices=num_indices,\n",
    "                                                  class_index=class_index,\n",
    "                                                  generator=stylex.G,\n",
    "                                                  classifier=classifier,\n",
    "                                                  all_dlatents=all_w,\n",
    "                                                  style_min=style_min,\n",
    "                                                  style_max=style_max,\n",
    "                                                  max_image_effect=effect_threshold*5,\n",
    "                                                  label_size=label_size_clasifier,\n",
    "                                                  sindex_offset=0)\n",
    "\n",
    "    s_indices_and_signs_dict[class_index] = s_indices_and_signs\n",
    "\n",
    "sindex_class_0 = [sindex for _, sindex in s_indices_and_signs_dict[0]]\n",
    "all_sindex_joined_class_0 = [(1 - direction, sindex) for direction, sindex in s_indices_and_signs_dict[1] if sindex not in sindex_class_0]\n",
    "all_sindex_joined_class_0 += s_indices_and_signs_dict[0]\n",
    "scores = []\n",
    "\n",
    "for direction, sindex in all_sindex_joined_class_0:\n",
    "    other_direction = 1 if direction == 0 else 0\n",
    "    curr_score = np.mean(style_change_effect[:, direction, sindex, 0]) + np.mean(style_change_effect[:, other_direction, sindex, 1])\n",
    "    scores.append(curr_score)\n",
    "\n",
    "s_indices_and_signs = [all_sindex_joined_class_0[i] for i in np.argsort(scores)[::-1]]\n",
    "\n",
    "print('Directions and style indices for moving from class 1 to class 0 = ', s_indices_and_signs[:num_indices])\n",
    "print('Use the other direction to move for class 0 to 1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:38.022234Z",
     "iopub.status.busy": "2022-02-02T13:16:38.021985Z",
     "iopub.status.idle": "2022-02-02T13:16:38.036663Z",
     "shell.execute_reply": "2022-02-02T13:16:38.035848Z",
     "shell.execute_reply.started": "2022-02-02T13:16:38.022199Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_user_study_img(tensor, upscale_res=None, nrow=2) -> None:\n",
    "    \"\"\"\n",
    "    Plots an image from a tensor.\n",
    "    \"\"\"\n",
    "    changed_tensor = tensor.clone()\n",
    "    if upscale_res is not None:\n",
    "        changed_tensor = resize(changed_tensor, upscale_res)\n",
    "\n",
    "\n",
    "    grid = make_grid(changed_tensor, nrow=nrow)\n",
    "    # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
    "    ndarr = grid.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "\n",
    "    return im\n",
    "\n",
    "def get_images(dlatent,\n",
    "                generator,\n",
    "                classifier,\n",
    "                sindex,\n",
    "                s_style_min,\n",
    "                s_style_max,\n",
    "                style_direction_index,\n",
    "                shift_size,\n",
    "                label_size,\n",
    "                noise, \n",
    "                cuda_rank):\n",
    "    \n",
    "    dlatent = [(torch.unsqueeze(torch.Tensor(dlatent).cuda(cuda_rank), 0), 5)]\n",
    "    w_latent_tensor = styles_def_to_tensor(dlatent)\n",
    "    generated_image, style_coords = generator(w_latent_tensor, noise, get_style_coords=True)\n",
    "\n",
    "    block_idx, weight_idx = sindex_to_block_idx_and_index(generator, sindex)\n",
    "    block = generator.blocks[block_idx]\n",
    "\n",
    "    current_style_layer = None\n",
    "    one_hot = None\n",
    "\n",
    "    if weight_idx < block.input_channels:\n",
    "        current_style_layer = block.to_style1\n",
    "        one_hot = torch.zeros((1, block.input_channels)).cuda(cuda_rank)\n",
    "    else:\n",
    "        weight_idx -= block.input_channels\n",
    "        current_style_layer = block.to_style2\n",
    "        one_hot = torch.zeros((1, block.filters)).cuda(cuda_rank)\n",
    "\n",
    "    one_hot[:, weight_idx] = 1\n",
    "\n",
    "\n",
    "    if style_direction_index == 0:\n",
    "        shift = one_hot * ((s_style_min - style_coords[:, sindex]) * shift_size).unsqueeze(1)\n",
    "    else:\n",
    "        shift = one_hot * ((s_style_max - style_coords[:, sindex]) * shift_size).unsqueeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        shift = shift.squeeze(0)\n",
    "        current_style_layer.bias += shift\n",
    "        changed_image, _ = generator(w_latent_tensor, noise, get_style_coords=True)\n",
    "        shift_logits = classifier.classify_images(changed_image)\n",
    "        current_style_layer.bias -= shift\n",
    "    \n",
    "    return generated_image, changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:16:57.015539Z",
     "iopub.status.busy": "2022-02-02T13:16:57.015251Z",
     "iopub.status.idle": "2022-02-02T13:16:57.027892Z",
     "shell.execute_reply": "2022-02-02T13:16:57.027181Z",
     "shell.execute_reply.started": "2022-02-02T13:16:57.015507Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_study1(stylex,\n",
    "                classifier,\n",
    "                gender,\n",
    "                top_attribute,\n",
    "                other_attribute,\n",
    "                s_indices_and_signs,\n",
    "                base_probs,\n",
    "                W_values,\n",
    "                style_min,\n",
    "                style_max,\n",
    "                shift_size,\n",
    "                label_size,\n",
    "                noise,\n",
    "                cuda_rank,\n",
    "                upscale_res):\n",
    "\n",
    "    if other_attribute >= len(s_indices_and_signs):\n",
    "        raise ValueError(\"That attribute is not included in the attribute list, it only includes %s images\" % len(s_indices_and_signs))\n",
    "    if gender == \"male\" or gender == \"female\":\n",
    "        gender_index = 0 if gender == \"male\" else 1\n",
    "    else:\n",
    "        raise ValueError(\"Please use either the male or female gender\")\n",
    "    \n",
    "    gender_indices = list(np.where(np.argmax(base_probs, axis=1) == gender_index)[0])\n",
    "    image_ids = random.sample(gender_indices, 4)\n",
    "    four_latents = W_values[image_ids]\n",
    "    \n",
    "    indices_and_signs = np.array([s_indices_and_signs[top_attribute]]*2 + random.sample([s_indices_and_signs[top_attribute],\n",
    "                                                                                s_indices_and_signs[other_attribute]], 2))\n",
    "    indices_and_signs = indices_and_signs[[0,2,1,3]]\n",
    "\n",
    "    g_images = []\n",
    "    c_images = []\n",
    "    \n",
    "    for index in range(4):\n",
    "        direction_index, style_index = indices_and_signs[index]\n",
    "        if gender_index == 0:\n",
    "            style_direction = 1 if direction_index == 0 else 0\n",
    "        else:\n",
    "            style_direction = direction_index\n",
    "        \n",
    "        generated_image, changed_image = get_images(four_latents[index],\n",
    "                                                    stylex.G,\n",
    "                                                    classifier,\n",
    "                                                    style_index,\n",
    "                                                    style_min[style_index],\n",
    "                                                    style_max[style_index],\n",
    "                                                    style_direction,\n",
    "                                                    shift_size,\n",
    "                                                    label_size,\n",
    "                                                    noise,\n",
    "                                                    cuda_rank)\n",
    "        g_images.append(generated_image)\n",
    "        c_images.append(changed_image)\n",
    "        \n",
    "    g_images = torch.cat(g_images)\n",
    "    c_images = torch.cat(c_images)\n",
    "        \n",
    "    if upscale_res != None:\n",
    "        g_images = generate_user_study_img(g_images, upscale_res=upscale_res, nrow=2)\n",
    "        c_images = generate_user_study_img(c_images, upscale_res=upscale_res, nrow=2)\n",
    "            \n",
    "    return [g_images, c_images], indices_and_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:20:27.236357Z",
     "iopub.status.busy": "2022-02-02T13:20:27.235914Z",
     "iopub.status.idle": "2022-02-02T13:20:27.369097Z",
     "shell.execute_reply": "2022-02-02T13:20:27.368331Z",
     "shell.execute_reply.started": "2022-02-02T13:20:27.236320Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k_range = 6\n",
    "# Render the images\n",
    "images_to_save = []\n",
    "info_of_images = []\n",
    "unique_attributes = list(range(top_k_range))\n",
    "random.shuffle(unique_attributes)\n",
    "for top_attribute in range(top_k_range):\n",
    "    gender = \"male\" if top_attribute % 2 == 0 else \"female\" \n",
    "    \n",
    "    for index, attr in enumerate(unique_attributes):\n",
    "        if attr != top_attribute:\n",
    "            other_attribute = unique_attributes.pop(index)\n",
    "            break\n",
    "    \n",
    "    images_to_render, attribute_info = user_study1(stylex = stylex,\n",
    "                                        classifier = classifier,\n",
    "                                        gender = gender,\n",
    "                                        top_attribute = top_attribute,\n",
    "                                        other_attribute = other_attribute,\n",
    "                                        s_indices_and_signs = s_indices_and_signs,\n",
    "                                        base_probs = base_probs,\n",
    "                                        W_values = W_values,\n",
    "                                        style_min = style_min,\n",
    "                                        style_max = style_max,\n",
    "                                        shift_size = 1,\n",
    "                                        label_size = 2,\n",
    "                                        noise = saved_noise,\n",
    "                                        cuda_rank = cuda_rank,\n",
    "                                        upscale_res=512)\n",
    "    \n",
    "    images_to_save.append(images_to_render)\n",
    "    info_of_images.append((attribute_info, (top_attribute, other_attribute)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import IPython.display as IPython_display\n",
    "\n",
    "# Save the images of user study 1 to disk\n",
    "# Check if user study directory exists, if not, create it\n",
    "user_study_dir = \"./user_study_images\"\n",
    "user_study1_dir = os.path.join(user_study_dir, \"study_1\")\n",
    "user_study2_dir = os.path.join(user_study_dir, \"study_2\")\n",
    "\n",
    "if not os.path.exists(user_study_dir):\n",
    "    os.makedirs(user_study_dir)\n",
    "\n",
    "    # Make a directory for each user study\n",
    "    os.makedirs(user_study1_dir)\n",
    "    os.makedirs(user_study2_dir)\n",
    "\n",
    "for index, (images, _) in enumerate(zip(images_to_save, info_of_images)):\n",
    "    file_path = os.path.join(user_study1_dir, f\"class_study_{index}.gif\")\n",
    "    imageio.mimsave(file_path, images, fps=1 + 1/3)\n",
    "    display(IPython_display.Image(filename=file_path))\n",
    "\n",
    "# Save the info_of_images to a text file\n",
    "with open(os.path.join(user_study1_dir, \"info_of_images.txt\"), \"w\") as f:\n",
    "    for directions_and_sindex, chosen_attributes in info_of_images:\n",
    "        target_attr = directions_and_sindex[0]\n",
    "        correct_answer = \"top-right\" if (target_attr == directions_and_sindex[1]).all() else \"bottom-right\"\n",
    "        f.write(f\"Same transformation in {correct_answer} \\n {chosen_attributes} \\n {str(directions_and_sindex)} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:17:15.397893Z",
     "iopub.status.busy": "2022-02-02T13:17:15.397615Z",
     "iopub.status.idle": "2022-02-02T13:17:15.410062Z",
     "shell.execute_reply": "2022-02-02T13:17:15.409208Z",
     "shell.execute_reply.started": "2022-02-02T13:17:15.397863Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_study2(stylex,\n",
    "                classifier,\n",
    "                top_attribute,\n",
    "                s_indices_and_signs,\n",
    "                W_values,\n",
    "                style_min,\n",
    "                style_max,\n",
    "                shift_size,\n",
    "                label_size,\n",
    "                noise,\n",
    "                cuda_rank,\n",
    "                upscale_res):\n",
    "    \n",
    "    image_ids = random.sample(range(len(W_values)), 4)\n",
    "    four_latents = W_values[image_ids]\n",
    "    \n",
    "    indices_and_signs = np.array([s_indices_and_signs[top_attribute]] * 4)\n",
    "    indices_and_signs = indices_and_signs[[0,2,1,3]] \n",
    "\n",
    "    g_images = []\n",
    "    c_images = []\n",
    "    \n",
    "    for index in range(4):\n",
    "        style_direction, style_index = indices_and_signs[index]\n",
    "\n",
    "        \n",
    "        generated_image, changed_image = get_images(four_latents[index],\n",
    "                                                    stylex.G,\n",
    "                                                    classifier,\n",
    "                                                    style_index,\n",
    "                                                    style_min[style_index],\n",
    "                                                    style_max[style_index],\n",
    "                                                    style_direction,\n",
    "                                                    shift_size,\n",
    "                                                    label_size,\n",
    "                                                    noise,\n",
    "                                                    cuda_rank)\n",
    "\n",
    "        g_images.append(generated_image)\n",
    "        c_images.append(changed_image)\n",
    "        \n",
    "    g_images = torch.cat(g_images)\n",
    "    c_images = torch.cat(c_images)\n",
    "        \n",
    "    if upscale_res != None:\n",
    "        g_images = generate_user_study_img(g_images, upscale_res=upscale_res, nrow=4)\n",
    "        c_images = generate_user_study_img(c_images, upscale_res=upscale_res, nrow=4)\n",
    "            \n",
    "    return [g_images, c_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_range = 6\n",
    "# Render the images\n",
    "images_to_save = []\n",
    "for top_attribute in range(top_k_range):\n",
    "    images_to_render = user_study2(stylex = stylex,\n",
    "                                    classifier = classifier,\n",
    "                                    top_attribute = top_attribute,\n",
    "                                    s_indices_and_signs = s_indices_and_signs,\n",
    "                                    W_values = W_values,\n",
    "                                    style_min = style_min,\n",
    "                                    style_max = style_max,\n",
    "                                    shift_size = 1,\n",
    "                                    label_size = 2,\n",
    "                                    noise = saved_noise,\n",
    "                                    cuda_rank = cuda_rank,\n",
    "                                    upscale_res=512)\n",
    "    \n",
    "    images_to_save.append(images_to_render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:17:17.473971Z",
     "iopub.status.busy": "2022-02-02T13:17:17.473468Z",
     "iopub.status.idle": "2022-02-02T13:17:18.234474Z",
     "shell.execute_reply": "2022-02-02T13:17:18.233688Z",
     "shell.execute_reply.started": "2022-02-02T13:17:17.473929Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "for index, image_to_render in enumerate(images_to_save):\n",
    "    for image, text in zip(image_to_render, [\"Before\", \"After\"]):\n",
    "        font = ImageFont.truetype(\"./Roboto-Bold.ttf\", size=30)\n",
    "        image_editable = ImageDraw.Draw(image)\n",
    "        image_editable.text((15,15), text, (255, 0, 0), font=font)\n",
    "    \n",
    "    file_path = os.path.join(user_study2_dir, f\"verbal_study_{index}.gif\")\n",
    "    imageio.mimsave(file_path, image_to_render, fps=1)\n",
    "    display(IPython_display.Image(filename=file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
